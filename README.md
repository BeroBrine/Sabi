# Sabi: A Shazam-like Audio Recognition Engine in Rust üéµ

Sabi is a high-performance, command-line audio recognition application written in Rust. It can listen to a short audio snippet (from a file or a microphone) and identify the song from a pre-populated database, similar to how Shazam works.

The project leverages a robust audio fingerprinting algorithm based on spectrogram peak analysis and uses a PostgreSQL database for efficient storage and retrieval of fingerprints.

## Table of Contents

- [How It Works](#how-it-works-)
  - [Phase 1: Ingestion](#phase-1-ingestion)
  - [Phase 2: Recognition](#phase-2-recognition)
- [Project Structure](#project-structure-)
- [Prerequisites](#prerequisites-)
- [Setup and Installation](#setup-and-installation-)
- [Usage](#usage-)
  - [Step 1: Download Songs](#step-1-download-songs-optional)
  - [Step 2: Ingest Songs into the Database](#step-2-ingest-songs-into-the-database)
  - [Step 3: Recognize a Song](#step-3-recognize-a-song)
- [Testing](#testing-)
- [Database Schema](#database-schema-)

---

## How It Works ‚öôÔ∏è

The core of Sabi is its audio fingerprinting algorithm, which condenses the unique characteristics of a song into a series of hashes that can be indexed and searched efficiently. The process is divided into two main phases.

### Phase 1: Ingestion

During ingestion, we build a "constellation map" of each song and store it in the database.

1. **Audio Decoding**: The audio file is decoded into raw audio samples.
2. **Preprocessing**: The samples are converted to mono, downsampled to a target rate (e.g., 11025 Hz), and a low-pass filter is applied to remove high-frequency noise. This standardization ensures that fingerprints are consistent.
3. **Spectrogram Generation**: The audio is analyzed in overlapping time windows. For each window, a Fast Fourier Transform (FFT) is applied to determine the intensity of different frequencies, creating a spectrogram.
4. **Peak Finding**: In each time window, we identify the strongest frequency peaks across several frequency bands (low, mid, high). These peaks form a "constellation map" of the song.
5. **Fingerprint Hashing**: We create combinatorial hashes by pairing an **anchor peak** with subsequent peaks in a **target zone**. Each hash is a unique identifier for a pair of peaks, encoding the anchor frequency, the target frequency, and the time delta between them.
   - `hash = H(freq_anchor, freq_target, Œîtime)`
6. **Database Storage**: Each generated fingerprint (`hash`, `anchor_time_offset`, `song_id`) is stored in the PostgreSQL database. An index on the `hash` column allows for extremely fast lookups.

### Phase 2: Recognition

When recognizing a snippet, we perform the same fingerprinting process and find which song in the database has the most matching fingerprints at a consistent time offset.

1. **Snippet Fingerprinting**: The incoming audio snippet (from a file or microphone) goes through the *exact same* pipeline as in the ingestion phase (Decode ‚Üí Preprocess ‚Üí Spectrogram ‚Üí Peak Finding ‚Üí Hashing).
2. **Database Lookup**: We query the database to find all stored fingerprints that share the same hashes as the ones generated from the snippet.
3. **Offset Matching & Voting**: For each match found, we calculate the time offset difference: `Œît = time_offset_in_db - time_offset_in_snippet`.
   - If the snippet is indeed from a song in our database, most of these `Œît` values will cluster around a single, consistent value (which represents when the snippet started playing in the original song).
4. **Histogram Analysis**: We use a histogram to count the occurrences of each `Œît` for every song. The song with the highest peak in its histogram is declared the winner.

---

## Project Structure üó∫Ô∏è

The codebase is organized into several modules, each with a specific responsibility.

| File/Directory | Description |
|---|---|
| `src/main.rs` | The application's entry point. Handles command-line argument parsing using `clap`. |
| `src/audio_processor.rs` | Manages all audio operations: decoding (`symphonia`), recording (`cpal`), resampling, and filtering. |
| `src/fft/` | Contains the custom implementation of the Cooley-Tukey Fast Fourier Transform (FFT) algorithm. |
| `src/fingerprint.rs` | Implements the core logic for generating fingerprints from FFT data and the histogram voting mechanism. |
| `src/db/` | Handles all database interactions via `diesel`, including connections, writing, and querying data. |
| `src/schema.rs` | Auto-generated by `diesel`, defining the Rust representation of the database tables. |
| `src/tester.rs` | Contains a comprehensive test suite to measure recognition accuracy on random song snippets. |
| `migrations/` | Contains SQL files for setting up and managing the database schema, managed by `diesel-cli`. |
| `scripts/` | Includes handy shell scripts for downloading, ingesting, and testing songs. |

---

## Prerequisites üõ†Ô∏è

Before you begin, ensure you have the following installed:

1. **Rust Toolchain**: Install via [rustup](https://rustup.rs/).
2. **PostgreSQL**: A running PostgreSQL server.
3. **Diesel CLI**: To manage database migrations.
   ```bash
   cargo install diesel_cli --no-default-features --features postgres
   ```
4. **`yt-dlp` & `ffmpeg`**: Required by the song downloader script.
   - **macOS (Homebrew)**: `brew install yt-dlp ffmpeg`
   - **Debian/Ubuntu**: `sudo apt install yt-dlp ffmpeg`
5. **PostgreSQL Development Libraries**:
   - **macOS (Homebrew)**: `brew install postgresql` (usually includes it).
   - **Debian/Ubuntu**: `sudo apt-get install libpq-dev`

---

## Setup and Installation üöÄ

1. **Clone the Repository**
   ```bash
   git clone https://github.com/BeroBrine/Sabi.git
   cd Sabi
   ```

2. **Configure the Database**
   - Create a user and a database in PostgreSQL.
   - Crate a .env file in root folder.
     ```bash
     touch .env
     ```
   - Edit the `.env` file and set your `DATABASE_URL`:
     ```
     DATABASE_URL=postgres://YOUR_USER:YOUR_PASSWORD@localhost/DATABASE
     ```

3. **Run Database Migrations**
   - This will set up the necessary tables (`songs`, `fingerprint`) in your database.
   ```bash
   diesel setup
   diesel migration run
   ```

4. **Build the Project**
   - Compile the project in release mode for optimal performance.
   ```bash
   cargo build --release
   ```

---

## Usage üé§

### Step 1: Download Songs (Optional)

You can use the provided script to easily download songs from YouTube for your library.

1. Create a file `scripts/song_list.txt`.
2. Add song names or search queries, one per line.
3. Run the script:
   ```bash
   cd scripts
   ./download_songs.sh
   ```
   Your songs will be saved as `.mp3` files in the `songs/` directory.

### Step 2: Ingest Songs into the Database

To recognize songs, you first need to process them and store their fingerprints. The `ingest_all.sh` script automates this for all songs in the `songs/` directory.

```bash
cd scripts
./ingest_all.sh
```

This script will reset the database and ingest each song one by one. For a single file, you can run:

```bash
cargo run --release -- --ingest --file "../songs/some_song_title.mp3"
```

### Step 3: Recognize a Song

#### From Microphone Input

This command will listen to your microphone for 5 seconds, process the audio, and print the best match.

```bash
cargo run --release -- --recognise
```

#### From an Audio File

If you have a snippet saved as an audio file, you can match it directly.

```bash
cargo run --release -- --match --file "path/to/your/snippet.mp3"
```

---

## Testing üß™

### Quick Live Test

The `test.sh` script provides a fun way to test the system. It picks a random song from your library, plays a 15-second snippet, and simultaneously runs the `--recognise` command to see if Sabi can identify it in real-time.

```bash
cd scripts
./test.sh
```

### Comprehensive Accuracy Test

For a more rigorous evaluation, use the `random-test` command. This will iterate through every song in your library, take multiple random 5-second snippets from each, and calculate the overall recognition accuracy.

```bash
# Point it to your songs directory
cargo run --release -- --random-test --file "songs"
```

---

## Database Schema üóÑÔ∏è

The database consists of two main tables defined in `migrations/2025-09-16-203052-0000_fingerprint/up.sql`.

### songs Table

Stores basic metadata about each ingested song.

```sql
CREATE TABLE songs (
  id SERIAL PRIMARY KEY,
  title VARCHAR(255) NOT NULL,
  created_at TIMESTAMP DEFAULT NOW()
);
```

### fingerprint Table

Stores the individual fingerprints. This is the core table used for matching.

```sql
CREATE TABLE fingerprint (
  hash BIGINT NOT NULL, 
  absolute_time_offset FLOAT NOT NULL,
  song_id INT NOT NULL REFERENCES songs(id) ON DELETE CASCADE,
  created_at TIMESTAMP DEFAULT NOW(),
  PRIMARY KEY (song_id, absolute_time_offset, hash)
);

-- An index on the hash is crucial for fast lookups
CREATE INDEX idx_fingerprint_hash ON fingerprint(hash);
```

- **hash**: The 64-bit combinatorial hash of a frequency peak pair.
- **absolute_time_offset**: The time in seconds where the anchor peak of the hash appeared in the song.
- **song_id**: A foreign key linking the fingerprint back to the songs table.
